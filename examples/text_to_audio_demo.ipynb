{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef09f1f1",
   "metadata": {},
   "source": [
    "# Text-to-Audio Project Demo\n",
    "\n",
    "This notebook provides a comprehensive demonstration of the text-to-audio conversion system using lightweight Hugging Face models.\n",
    "\n",
    "## Features Covered:\n",
    "- Text preprocessing and tokenization\n",
    "- TTS model integration\n",
    "- Audio processing and output\n",
    "- Dataset management\n",
    "- Interactive examples with visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c79eb27",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7289ba01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "from IPython.display import Audio, display, HTML\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add src directory to path\n",
    "project_root = Path.cwd().parent if Path.cwd().name == 'examples' else Path.cwd()\n",
    "sys.path.append(str(project_root / \"src\"))\n",
    "\n",
    "# Import our modules\n",
    "from text_processor import TextProcessor\n",
    "from tts_model import TTSModelManager\n",
    "from audio_processor import AudioProcessor\n",
    "from main import TextToAudioConverter\n",
    "from dataset_manager import DatasetManager\n",
    "\n",
    "print(\"‚úÖ All imports successful!\")\n",
    "print(f\"Project root: {project_root}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05312ed0",
   "metadata": {},
   "source": [
    "## 1. Text Processing Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc51e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize text processor\n",
    "text_processor = TextProcessor()\n",
    "\n",
    "# Sample text with various challenges\n",
    "sample_text = \"Hello Dr. Smith! Today is 25¬∞C. Please visit www.example.com at 3:30 PM on Jan. 1st, 2024. We have 5 cats & 3 dogs.\"\n",
    "\n",
    "print(\"üìù Text Processing Demo\")\n",
    "print(\"=\" * 30)\n",
    "print(f\"Original text: {sample_text}\")\n",
    "print()\n",
    "\n",
    "# Clean text\n",
    "cleaned_text = text_processor.clean_text(sample_text)\n",
    "print(f\"Cleaned text: {cleaned_text}\")\n",
    "print()\n",
    "\n",
    "# Get text statistics\n",
    "stats = text_processor.get_text_stats(sample_text)\n",
    "print(\"Text Statistics:\")\n",
    "for key, value in stats.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "print()\n",
    "\n",
    "# Preprocess for TTS\n",
    "tts_chunks = text_processor.preprocess_for_tts(sample_text)\n",
    "print(f\"TTS Chunks ({len(tts_chunks)}):\")\n",
    "for i, chunk in enumerate(tts_chunks, 1):\n",
    "    print(f\"  {i}. {chunk}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c613b2f",
   "metadata": {},
   "source": [
    "## 2. TTS Model Integration Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a8b0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize TTS model\n",
    "print(\"ü§ñ Initializing TTS Model...\")\n",
    "tts_model = TTSModelManager()\n",
    "\n",
    "# Get model information\n",
    "model_info = tts_model.get_model_info()\n",
    "print(\"\\nüìä Model Information:\")\n",
    "for key, value in model_info.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# List available models\n",
    "available_models = tts_model.list_available_models()\n",
    "print(f\"\\nüîç Available Models: {available_models}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e14cb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate speech from text\n",
    "test_text = \"This is a demonstration of text to speech synthesis using Hugging Face models.\"\n",
    "print(f\"üéµ Generating audio for: '{test_text}'\")\n",
    "\n",
    "# Synthesize speech\n",
    "audio_data = tts_model.synthesize_speech(test_text)\n",
    "\n",
    "if audio_data is not None:\n",
    "    print(f\"‚úÖ Audio generated successfully!\")\n",
    "    print(f\"   Shape: {audio_data.shape}\")\n",
    "    print(f\"   Duration: {len(audio_data) / tts_model.get_sample_rate():.2f} seconds\")\n",
    "    \n",
    "    # Play audio in notebook\n",
    "    display(Audio(audio_data, rate=tts_model.get_sample_rate()))\n",
    "else:\n",
    "    print(\"‚ùå Audio generation failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f709468d",
   "metadata": {},
   "source": [
    "## 3. Audio Processing and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef12b5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize audio processor\n",
    "audio_processor = AudioProcessor()\n",
    "\n",
    "if audio_data is not None:\n",
    "    # Get audio information\n",
    "    audio_info = audio_processor.get_audio_info(audio_data, tts_model.get_sample_rate())\n",
    "    print(\"üîä Audio Information:\")\n",
    "    for key, value in audio_info.items():\n",
    "        if isinstance(value, float):\n",
    "            print(f\"  {key}: {value:.4f}\")\n",
    "        else:\n",
    "            print(f\"  {key}: {value}\")\n",
    "    \n",
    "    # Apply audio processing\n",
    "    print(\"\\nüéõÔ∏è Applying audio processing...\")\n",
    "    processed_audio = audio_processor.apply_fade(audio_data, sample_rate=tts_model.get_sample_rate())\n",
    "    processed_audio = audio_processor.normalize_audio(processed_audio)\n",
    "    \n",
    "    print(\"‚úÖ Audio processing completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3806e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize audio waveform and spectrogram\n",
    "if audio_data is not None:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Original waveform\n",
    "    axes[0, 0].plot(audio_data)\n",
    "    axes[0, 0].set_title('Original Audio Waveform')\n",
    "    axes[0, 0].set_xlabel('Samples')\n",
    "    axes[0, 0].set_ylabel('Amplitude')\n",
    "    \n",
    "    # Processed waveform\n",
    "    axes[0, 1].plot(processed_audio)\n",
    "    axes[0, 1].set_title('Processed Audio Waveform')\n",
    "    axes[0, 1].set_xlabel('Samples')\n",
    "    axes[0, 1].set_ylabel('Amplitude')\n",
    "    \n",
    "    # Spectrogram\n",
    "    D = librosa.stft(audio_data)\n",
    "    S_db = librosa.amplitude_to_db(np.abs(D), ref=np.max)\n",
    "    librosa.display.specshow(S_db, x_axis='time', y_axis='hz', ax=axes[1, 0])\n",
    "    axes[1, 0].set_title('Spectrogram')\n",
    "    \n",
    "    # Mel spectrogram\n",
    "    S = librosa.feature.melspectrogram(y=audio_data, sr=tts_model.get_sample_rate())\n",
    "    S_db_mel = librosa.amplitude_to_db(S, ref=np.max)\n",
    "    librosa.display.specshow(S_db_mel, x_axis='time', y_axis='mel', ax=axes[1, 1])\n",
    "    axes[1, 1].set_title('Mel Spectrogram')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Save the processed audio\n",
    "    output_path = audio_processor.save_audio(\n",
    "        processed_audio, \n",
    "        \"notebook_demo\", \n",
    "        tts_model.get_sample_rate()\n",
    "    )\n",
    "    print(f\"\\nüíæ Audio saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78046a28",
   "metadata": {},
   "source": [
    "## 4. Complete Text-to-Audio Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f6d43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the complete converter\n",
    "print(\"üîß Initializing Text-to-Audio Converter...\")\n",
    "converter = TextToAudioConverter()\n",
    "\n",
    "# Get system information\n",
    "system_info = converter.get_system_info()\n",
    "print(\"\\nüìã System Configuration:\")\n",
    "print(f\"  Model: {system_info['model_name']}\")\n",
    "print(f\"  Device: {system_info['device']}\")\n",
    "print(f\"  Output Directory: {system_info['output_dir']}\")\n",
    "print(f\"  Audio Format: {system_info['config']['audio_format']}\")\n",
    "\n",
    "# Component status\n",
    "components = system_info['components_initialized']\n",
    "print(\"\\nüß© Component Status:\")\n",
    "for component, status in components.items():\n",
    "    status_icon = \"‚úÖ\" if status else \"‚ùå\"\n",
    "    print(f\"  {status_icon} {component}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5920a2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo: Convert various types of text\n",
    "demo_texts = [\n",
    "    \"Hello! This is a simple greeting.\",\n",
    "    \"The quick brown fox jumps over the lazy dog. This sentence contains every letter of the alphabet.\",\n",
    "    \"In 2024, AI technology advanced significantly. Dr. Johnson's research at MIT showed promising results.\",\n",
    "    \"Welcome to our interactive demo! Today we'll explore text-to-speech synthesis using state-of-the-art models.\"\n",
    "]\n",
    "\n",
    "print(\"üéØ Converting Multiple Text Examples...\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "audio_outputs = []\n",
    "\n",
    "for i, text in enumerate(demo_texts, 1):\n",
    "    print(f\"\\nüìù Example {i}: {text[:50]}...\")\n",
    "    \n",
    "    # Convert text to audio\n",
    "    output_path = converter.convert_text(text, f\"demo_example_{i}\")\n",
    "    \n",
    "    if output_path:\n",
    "        print(f\"‚úÖ Success: {Path(output_path).name}\")\n",
    "        \n",
    "        # Load and display audio\n",
    "        audio_data, sample_rate = audio_processor.load_audio(output_path)\n",
    "        audio_outputs.append((audio_data, sample_rate, text))\n",
    "        \n",
    "        # Show audio player\n",
    "        display(HTML(f\"<b>üéµ Audio for Example {i}:</b>\"))\n",
    "        display(Audio(audio_data, rate=sample_rate))\n",
    "        \n",
    "        # Quick statistics\n",
    "        duration = len(audio_data) / sample_rate\n",
    "        word_count = len(text.split())\n",
    "        print(f\"   Duration: {duration:.2f}s, Words: {word_count}, Rate: {word_count/duration*60:.0f} words/min\")\n",
    "    else:\n",
    "        print(f\"‚ùå Failed to convert example {i}\")\n",
    "\n",
    "print(f\"\\nüéâ Completed {len([a for a in audio_outputs if a])} out of {len(demo_texts)} conversions!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b8fdb7",
   "metadata": {},
   "source": [
    "## 5. Dataset Management Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1464110b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dataset manager\n",
    "print(\"üìä Dataset Management Demo\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "dataset_manager = DatasetManager()\n",
    "\n",
    "# List available datasets\n",
    "available_datasets = dataset_manager.list_available_datasets()\n",
    "print(\"Available Datasets:\")\n",
    "for name, info in available_datasets.items():\n",
    "    print(f\"  üìÅ {name}: {info['name']}\")\n",
    "    print(f\"     Type: {info['type']}, Language: {info['language']}\")\n",
    "    print(f\"     Sample Rate: {info['sample_rate']} Hz, Size: {info['size']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03c3863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a small sample of LJSpeech for demonstration\n",
    "print(\"üì• Loading LJSpeech dataset (limited sample)...\")\n",
    "\n",
    "try:\n",
    "    # Load just a few samples for demo purposes\n",
    "    ljspeech_sample = dataset_manager.load_ljspeech(max_samples=5)\n",
    "    \n",
    "    if ljspeech_sample:\n",
    "        print(f\"‚úÖ Loaded {len(ljspeech_sample)} samples\")\n",
    "        \n",
    "        # Show sample data\n",
    "        print(\"\\nüìã Sample Data:\")\n",
    "        for i in range(min(3, len(ljspeech_sample))):\n",
    "            sample = ljspeech_sample[i]\n",
    "            print(f\"\\nSample {i+1}:\")\n",
    "            print(f\"  Text: {sample['text'][:100]}...\")\n",
    "            if 'audio' in sample:\n",
    "                audio_info = sample['audio']\n",
    "                duration = len(audio_info['array']) / audio_info['sampling_rate']\n",
    "                print(f\"  Audio: {duration:.2f}s, {audio_info['sampling_rate']} Hz\")\n",
    "                \n",
    "                # Play first sample\n",
    "                if i == 0:\n",
    "                    print(\"  üéµ Playing first sample:\")\n",
    "                    display(Audio(audio_info['array'], rate=audio_info['sampling_rate']))\n",
    "        \n",
    "        # Get dataset statistics\n",
    "        stats = dataset_manager.get_dataset_stats('ljspeech')\n",
    "        if stats:\n",
    "            print(\"\\nüìä Dataset Statistics:\")\n",
    "            print(f\"  Total samples: {stats['total_samples']}\")\n",
    "            if 'text_stats' in stats:\n",
    "                ts = stats['text_stats']\n",
    "                print(f\"  Avg words per text: {ts['avg_words']:.1f}\")\n",
    "                print(f\"  Text length range: {ts['min_chars']}-{ts['max_chars']} chars\")\n",
    "            if 'audio_stats' in stats:\n",
    "                aus = stats['audio_stats']\n",
    "                print(f\"  Avg duration: {aus['avg_duration']:.2f}s\")\n",
    "                print(f\"  Sample rates: {aus['sample_rates']}\")\n",
    "    else:\n",
    "        print(\"‚ùå Failed to load dataset\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Dataset loading encountered an issue: {e}\")\n",
    "    print(\"This is normal for demo purposes - full datasets are large!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9bf142f",
   "metadata": {},
   "source": [
    "## 6. Interactive Audio Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42dc8e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different processing settings\n",
    "print(\"üîÑ Audio Processing Comparison\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "comparison_text = \"This text will be processed with different audio settings to demonstrate the effects of various processing options.\"\n",
    "\n",
    "# Different configurations to test\n",
    "configs = [\n",
    "    {\"name\": \"Default\", \"settings\": {}},\n",
    "    {\"name\": \"With Fade\", \"settings\": {\"apply_fade\": True}},\n",
    "    {\"name\": \"Normalized\", \"settings\": {\"normalize_audio\": True}},\n",
    "    {\"name\": \"Full Processing\", \"settings\": {\"apply_fade\": True, \"normalize_audio\": True, \"noise_reduction\": True}}\n",
    "]\n",
    "\n",
    "comparison_results = []\n",
    "\n",
    "for config in configs:\n",
    "    print(f\"\\nüéõÔ∏è Testing: {config['name']}\")\n",
    "    \n",
    "    # Update converter configuration\n",
    "    converter.update_config(**config['settings'])\n",
    "    \n",
    "    # Convert text\n",
    "    output_path = converter.convert_text(comparison_text, f\"comparison_{config['name'].lower().replace(' ', '_')}\")\n",
    "    \n",
    "    if output_path:\n",
    "        audio_data, sample_rate = audio_processor.load_audio(output_path)\n",
    "        comparison_results.append({\n",
    "            \"name\": config['name'],\n",
    "            \"audio\": audio_data,\n",
    "            \"sample_rate\": sample_rate,\n",
    "            \"path\": output_path\n",
    "        })\n",
    "        \n",
    "        print(f\"‚úÖ Generated: {Path(output_path).name}\")\n",
    "        \n",
    "        # Display audio player\n",
    "        display(HTML(f\"<b>üéµ {config['name']} Processing:</b>\"))\n",
    "        display(Audio(audio_data, rate=sample_rate))\n",
    "    else:\n",
    "        print(f\"‚ùå Failed: {config['name']}\")\n",
    "\n",
    "print(f\"\\nüéâ Generated {len(comparison_results)} comparison samples!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e23208b",
   "metadata": {},
   "source": [
    "## 7. Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff59ecf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Performance testing\n",
    "print(\"‚ö° Performance Analysis\")\n",
    "print(\"=\" * 25)\n",
    "\n",
    "# Test different text lengths\n",
    "test_texts = [\n",
    "    \"Short text.\",\n",
    "    \"This is a medium length text that contains several words and should take a moderate amount of time to process.\",\n",
    "    \"This is a much longer text sample that we will use to test the performance of our text-to-speech system with extended content. It contains multiple sentences and should provide a good benchmark for processing longer documents. The system should handle this efficiently while maintaining good audio quality throughout the entire conversion process.\"\n",
    "]\n",
    "\n",
    "performance_results = []\n",
    "\n",
    "for i, text in enumerate(test_texts, 1):\n",
    "    word_count = len(text.split())\n",
    "    char_count = len(text)\n",
    "    \n",
    "    print(f\"\\nüìù Test {i}: {word_count} words, {char_count} characters\")\n",
    "    \n",
    "    # Time the conversion\n",
    "    start_time = time.time()\n",
    "    output_path = converter.convert_text(text, f\"perf_test_{i}\")\n",
    "    end_time = time.time()\n",
    "    \n",
    "    conversion_time = end_time - start_time\n",
    "    \n",
    "    if output_path:\n",
    "        # Get audio duration\n",
    "        audio_data, sample_rate = audio_processor.load_audio(output_path)\n",
    "        audio_duration = len(audio_data) / sample_rate\n",
    "        \n",
    "        # Calculate metrics\n",
    "        real_time_factor = conversion_time / audio_duration\n",
    "        words_per_second = word_count / conversion_time\n",
    "        \n",
    "        result = {\n",
    "            \"test_id\": i,\n",
    "            \"word_count\": word_count,\n",
    "            \"char_count\": char_count,\n",
    "            \"conversion_time\": conversion_time,\n",
    "            \"audio_duration\": audio_duration,\n",
    "            \"real_time_factor\": real_time_factor,\n",
    "            \"words_per_second\": words_per_second\n",
    "        }\n",
    "        \n",
    "        performance_results.append(result)\n",
    "        \n",
    "        print(f\"   ‚è±Ô∏è Conversion time: {conversion_time:.2f}s\")\n",
    "        print(f\"   üéµ Audio duration: {audio_duration:.2f}s\")\n",
    "        print(f\"   üìä Real-time factor: {real_time_factor:.2f}x\")\n",
    "        print(f\"   üöÄ Processing speed: {words_per_second:.1f} words/sec\")\n",
    "    else:\n",
    "        print(f\"   ‚ùå Conversion failed\")\n",
    "\n",
    "# Summary\n",
    "if performance_results:\n",
    "    avg_rtf = np.mean([r['real_time_factor'] for r in performance_results])\n",
    "    avg_wps = np.mean([r['words_per_second'] for r in performance_results])\n",
    "    \n",
    "    print(f\"\\nüìä Average Performance:\")\n",
    "    print(f\"   Real-time factor: {avg_rtf:.2f}x\")\n",
    "    print(f\"   Processing speed: {avg_wps:.1f} words/sec\")\n",
    "    \n",
    "    if avg_rtf < 1.0:\n",
    "        print(\"   ‚úÖ System runs faster than real-time!\")\n",
    "    else:\n",
    "        print(\"   ‚è≥ System runs slower than real-time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05b27f2",
   "metadata": {},
   "source": [
    "## 8. Cleanup and Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b9e5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup resources\n",
    "print(\"üßπ Cleaning up resources...\")\n",
    "\n",
    "if 'tts_model' in locals():\n",
    "    tts_model.cleanup()\n",
    "\n",
    "if 'converter' in locals():\n",
    "    converter.cleanup()\n",
    "\n",
    "if 'audio_processor' in locals():\n",
    "    audio_processor.cleanup()\n",
    "\n",
    "print(\"‚úÖ Cleanup completed!\")\n",
    "\n",
    "# Summary\n",
    "print(\"\\nüéâ Notebook Demo Summary\")\n",
    "print(\"=\" * 30)\n",
    "print(\"Features demonstrated:\")\n",
    "print(\"  ‚úÖ Text preprocessing and tokenization\")\n",
    "print(\"  ‚úÖ TTS model integration\")\n",
    "print(\"  ‚úÖ Audio processing and visualization\")\n",
    "print(\"  ‚úÖ Complete text-to-audio pipeline\")\n",
    "print(\"  ‚úÖ Dataset management\")\n",
    "print(\"  ‚úÖ Interactive audio comparison\")\n",
    "print(\"  ‚úÖ Performance analysis\")\n",
    "print(\"\\nüöÄ The text-to-audio system is ready for use!\")\n",
    "\n",
    "# List generated files\n",
    "output_dir = Path(\"../output\")\n",
    "if output_dir.exists():\n",
    "    audio_files = list(output_dir.glob(\"*.wav\"))\n",
    "    if audio_files:\n",
    "        print(f\"\\nüìÅ Generated {len(audio_files)} audio files:\")\n",
    "        for file_path in sorted(audio_files)[-5:]:  # Show last 5 files\n",
    "            size_kb = file_path.stat().st_size / 1024\n",
    "            print(f\"   üìÑ {file_path.name} ({size_kb:.1f} KB)\")\n",
    "        if len(audio_files) > 5:\n",
    "            print(f\"   ... and {len(audio_files) - 5} more files\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
